{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f012124",
   "metadata": {},
   "source": [
    "# Scraping Top Repositories for Github Topics\n",
    "- Scraping the top repositories for top 30 most popular topics on Github\n",
    "- Tools and Libraries used:\n",
    "  * Python\n",
    "  * Pandas\n",
    "  * Requests\n",
    "  * Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9499019c",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "* We are going to scrape https://github.com/topics.\n",
    "* We will get a list of 30 topics and for each topic we will get it's title, URL and description.\n",
    "* For each topic we will get top 20 repositories.\n",
    "* For each repositories, we will get the repo name, it's owner, URL and number of stars.\n",
    "* For each topic we will create a CSV file and store the above data.\n",
    "* Example of CSV format:\n",
    "                Year,Make,Model\n",
    "                1997,Ford,E350\n",
    "                2000,Mercury,Cougar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0b189",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3517bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333707d6",
   "metadata": {},
   "source": [
    "## Scraping the list of topics from Github\n",
    "- Use requests to get the web page\n",
    "- Use blacksoup to parse and extract information from the HTML\n",
    "- Convert it into a pandas Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba038ce",
   "metadata": {},
   "source": [
    "### Using requests library to get the web page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e6eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_url = 'https://github.com/topics'\n",
    "res = req.get(topic_url)\n",
    "page_content=res.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb159f9",
   "metadata": {},
   "source": [
    "### Using Blacksoup to parse the page and getting the required tags containing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "926e2c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_page=BeautifulSoup(page_content,'html.parser')\n",
    "\n",
    "topic_title_tags=parsed_page.find_all('p',{'class':'f3 lh-condensed mb-0 mt-1 Link--primary'})\n",
    "\n",
    "title_desc_tags=parsed_page.find_all('p',{'class':'f5 color-fg-muted mb-0 mt-1'})\n",
    "\n",
    "title_links_tags=parsed_page.find_all('a',{'class':'no-underline flex-1 d-flex flex-column'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b6d77",
   "metadata": {},
   "source": [
    "### Converting the information in the tag to lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f3f87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_links=[]\n",
    "for link in title_links_tags:\n",
    "    topic_links.append(\"https://github.com\"+link['href'])\n",
    "\n",
    "topic_text=[]\n",
    "for txt in topic_title_tags:\n",
    "    topic_text.append(txt.text)\n",
    "\n",
    "topic_desc=[]\n",
    "for desc in title_desc_tags:\n",
    "    topic_desc.append(desc.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e8418",
   "metadata": {},
   "source": [
    "### Converting the lists to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aae6e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3D</td>\n",
       "      <td>3D modeling is the process of virtually develo...</td>\n",
       "      <td>https://github.com/topics/3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajax</td>\n",
       "      <td>Ajax is a technique for creating interactive w...</td>\n",
       "      <td>https://github.com/topics/ajax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algorithm</td>\n",
       "      <td>Algorithms are self-contained sequences that c...</td>\n",
       "      <td>https://github.com/topics/algorithm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amp</td>\n",
       "      <td>Amp is a non-blocking concurrency library for ...</td>\n",
       "      <td>https://github.com/topics/amphp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Android</td>\n",
       "      <td>Android is an operating system built by Google...</td>\n",
       "      <td>https://github.com/topics/android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                        description  \\\n",
       "0         3D  3D modeling is the process of virtually develo...   \n",
       "1       Ajax  Ajax is a technique for creating interactive w...   \n",
       "2  Algorithm  Algorithms are self-contained sequences that c...   \n",
       "3        Amp  Amp is a non-blocking concurrency library for ...   \n",
       "4    Android  Android is an operating system built by Google...   \n",
       "\n",
       "                                   url  \n",
       "0         https://github.com/topics/3d  \n",
       "1       https://github.com/topics/ajax  \n",
       "2  https://github.com/topics/algorithm  \n",
       "3      https://github.com/topics/amphp  \n",
       "4    https://github.com/topics/android  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dict={\n",
    "    'title':topic_text,\n",
    "    'description':topic_desc,\n",
    "    'url':topic_links\n",
    "}\n",
    "\n",
    "topics_df = pd.DataFrame(topic_dict)\n",
    "\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91b0ea3",
   "metadata": {},
   "source": [
    "## Scraping the top 20 repositories for each topic\n",
    "Defining functions for:\n",
    "   - Getting the web page through requests and parsing it through beautifulsoup\n",
    "   - Getting necessary information from the page\n",
    "   - Converting the information to a data frame\n",
    "   - Storing all the data frame as CSV in a separate folder using OS library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96893619",
   "metadata": {},
   "source": [
    "### Getting the web page and parsing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78eae303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_repo(url):\n",
    "    response=req.get(url)\n",
    "    if(response.status_code != 200):\n",
    "        raise Exception('Error getting the page')\n",
    "    web_page=BeautifulSoup(response.text,'html.parser')\n",
    "    repo_headings=web_page.find_all('h3',{'class':'f3 color-fg-muted text-normal lh-condensed'})\n",
    "    stars_tags=web_page.find_all('span',{'id':'repo-stars-counter-star'})\n",
    "    return repo_headings,stars_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eeb4a1",
   "metadata": {},
   "source": [
    "### Getting repository information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76d3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repo_info (h3_tags,stars_tags):\n",
    "    username = h3_tags.find_all('a')[0].text.strip()\n",
    "    repo_name = h3_tags.find_all('a')[1].text.strip()\n",
    "    repo_url = \"https://github.com\"+h3_tags.find_all('a')[1]['href']\n",
    "    stars = stars_tags.text\n",
    "    return username,repo_name,repo_url,stars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f112846",
   "metadata": {},
   "source": [
    "### Converting the information into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f228b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(url):\n",
    "    topic_repo_dict = {\n",
    "    'username':[],\n",
    "    'repo_name':[],\n",
    "    'url':[],\n",
    "    'stars':[]\n",
    "    }\n",
    "    repo_headings,stars_tags=get_topic_repo(url)\n",
    "    for i in range(len(repo_headings)):\n",
    "        repo_info=get_repo_info(repo_headings[i],stars_tags[i])\n",
    "        topic_repo_dict['username'].append(repo_info[0])\n",
    "        topic_repo_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repo_dict['url'].append(repo_info[2])\n",
    "        topic_repo_dict['stars'].append(repo_info[3])\n",
    "\n",
    "    return pd.DataFrame(topic_repo_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a172a9",
   "metadata": {},
   "source": [
    "### Saving all the dataframes as CSVs in a separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b76465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topic_repos():\n",
    "    os.makedirs('topic-wise_datasets',exist_ok=True)\n",
    "    for index,row in topics_df.iterrows():\n",
    "        path='topic-wise_datasets/'+row['title']+'.csv'\n",
    "        if os.path.exists(path):\n",
    "            print(\"File {} already exists. Skipping....\".format(row['title']))\n",
    "            continue\n",
    "        print('Scraping the repo \"{}\"...'.format(row['title']))\n",
    "        df=get_dataframe(row['url'])\n",
    "        df.to_csv(path,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0962bf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping the repo \"3D\"...\n",
      "Scraping the repo \"Ajax\"...\n",
      "Scraping the repo \"Algorithm\"...\n",
      "Scraping the repo \"Amp\"...\n",
      "Scraping the repo \"Android\"...\n",
      "Scraping the repo \"Angular\"...\n",
      "Scraping the repo \"Ansible\"...\n",
      "Scraping the repo \"API\"...\n",
      "Scraping the repo \"Arduino\"...\n",
      "Scraping the repo \"ASP.NET\"...\n",
      "Scraping the repo \"Atom\"...\n",
      "Scraping the repo \"Awesome Lists\"...\n",
      "Scraping the repo \"Amazon Web Services\"...\n",
      "Scraping the repo \"Azure\"...\n",
      "Scraping the repo \"Babel\"...\n",
      "Scraping the repo \"Bash\"...\n",
      "Scraping the repo \"Bitcoin\"...\n",
      "Scraping the repo \"Bootstrap\"...\n",
      "Scraping the repo \"Bot\"...\n",
      "Scraping the repo \"C\"...\n",
      "Scraping the repo \"Chrome\"...\n",
      "Scraping the repo \"Chrome extension\"...\n",
      "Scraping the repo \"Command line interface\"...\n",
      "Scraping the repo \"Clojure\"...\n",
      "Scraping the repo \"Code quality\"...\n",
      "Scraping the repo \"Code review\"...\n",
      "Scraping the repo \"Compiler\"...\n",
      "Scraping the repo \"Continuous integration\"...\n",
      "Scraping the repo \"COVID-19\"...\n",
      "Scraping the repo \"C++\"...\n"
     ]
    }
   ],
   "source": [
    "scrape_topic_repos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
